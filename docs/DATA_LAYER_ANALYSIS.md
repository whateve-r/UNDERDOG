# Capa de Datos - An√°lisis Papers y Metodolog√≠as de Inyecci√≥n

## üìä Resumen Ejecutivo

Basado en an√°lisis de papers cient√≠ficos (arXiv:2510.04952v2, arXiv:2510.10526v1, arXiv:2510.03236v1, AlphaQuanter.pdf), la capa de datos √≥ptima combina:

1. **Datos estructurados** (OHLCV, volatilidad realizada)
2. **Datos no estructurados** (sentiment LLM, noticias)
3. **Datos fundamentales/macro** (SEC, FRED)

**Problema identificado:** Tu enfoque actual (broker backfill + async stream) es correcto para OHLCV, pero **carece de alternative data** (sentiment, macro) que los papers demuestran cr√≠tico para performance.

**Soluci√≥n:** Arquitectura h√≠brida con **Feature Store centralizado** + **LLM Orchestrator** (patr√≥n AlphaQuanter).

---

## üìã Metodolog√≠as de Papers (Desglose T√©cnico)

### Paper 1: arXiv:2510.03236v1 (Regime-Switching Volatility)

**Datos Usados:**
```
Input: Retornos logar√≠tmicos de 5 minutos
Features Engineering:
- RV (Realized Volatility): Suma de retornos¬≤ intradiarios
- HAR features: RV_daily, RV_weekly, RV_monthly
- R√©gimen hist√≥rico (clustering GMM)

Frecuencia: 5-min bars ‚Üí agregaci√≥n diaria para RV
Source: No especificado (probablemente Reuters/Bloomberg tick data)
```

**Costo:** 
- Tick data hist√≥rico: **$500-2000/a√±o** por s√≠mbolo (comercial)
- Alternativa gratuita: **1-min bars** de yfinance/MT5 ‚Üí calcular RV equivalente

**Implementaci√≥n Python:**
```python
# Calcular Realized Volatility (RV) desde 1-min bars
returns = np.log(df['close'] / df['close'].shift(1))
rv_daily = returns.rolling(window=1440).apply(lambda x: (x**2).sum())  # 1440 min = 1 d√≠a
```

**Eficiencia:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (cr√≠tico para regime detection)

---

### Paper 2: arXiv:2510.10526v1 (LLM + RL Integration)

**Datos Usados:**
```
Structured Data:
- OHLC 1-hour bars
- Technical indicators: MACD, RSI, Bollinger Bands
- Market volume

Unstructured Data (CR√çTICO):
- News headlines (Reuters, Bloomberg, Twitter/X)
- Sentiment score via FinGPT: [-1, 1]
  * -1 = bearish, 0 = neutral, 1 = bullish

Feature Vector:
state = [price_t, MACD_t, RSI_t, sentiment_t, volume_t]
```

**Metodolog√≠a de Sentiment:**
1. **Recolecci√≥n:** Web scraping de titulares financieros (√∫ltimas 24h)
2. **Procesamiento:** FinGPT (Hugging Face: `fingpt-forecaster`)
3. **Agregaci√≥n:** Promedio ponderado por tiempo (m√°s reciente = m√°s peso)
4. **Latencia:** Actualizaci√≥n cada 1 hora (suficiente para 1h bars)

**Costo:**
- FinGPT model: **GRATUITO** (Hugging Face)
- News sources:
  * **Gratuito:** RSS feeds (Investing.com, FXStreet, Reddit r/forex)
  * **Comercial:** NewsAPI ($449/mes), Alpha Vantage News ($50/mes)
  * **H√≠brido:** Twitter/X API v2 Free Tier (100 requests/mes)

**Implementaci√≥n Python:**
```python
from transformers import pipeline

# FinGPT sentiment pipeline
sentiment_analyzer = pipeline(
    "sentiment-analysis",
    model="FinGPT/fingpt-sentiment-lora-7b",
    device=0  # GPU
)

# Process news
headlines = scrape_news_last_24h("EURUSD")  # Custom scraper
sentiment_scores = [sentiment_analyzer(h)[0]['score'] for h in headlines]
avg_sentiment = np.mean(sentiment_scores)
```

**Eficiencia:** ‚≠ê‚≠ê‚≠ê‚≠ê‚òÜ (high impact, moderate complexity)

---

### Paper 3: arXiv:2510.04952v2 (Safe Execution - No datos alternativos)

**Datos Usados:**
```
SOLO datos de ejecuci√≥n:
- Order book depth (L2 market data)
- Spread bid-ask
- Transaction costs

NO usa sentiment ni news (enfoque puro en microestructura)
```

**Costo:** Order book L2 = **$1000+/mes** (Dukascopy, CQG)

**Relevancia para tu proyecto:** BAJA (ya tienes spread de MT5)

---

### AlphaQuanter Framework (uploaded:alphaquanter.pdf)

**Datos Usados (LLM Orchestrator):**
```
Multi-Source Architecture:
1. Price Data:
   - Yahoo Finance (yfinance): OHLCV gratuito
   - Timeframe: daily/hourly

2. Fundamental Data:
   - SEC Edgar: Insider transactions (GRATUITO)
   - Balance sheets, earnings (via yfinance)

3. Sentiment Data:
   - News scraping (BeautifulSoup)
   - Twitter/X API
   - Reddit (PRAW)

4. Macro Indicators:
   - FRED API: Fed Funds Rate, Unemployment, GDP
   - VIX (volatility index)

Feature Store:
- InfluxDB (time-series DB)
- Redis (cache for LLM queries)
```

**Patr√≥n de Orquestaci√≥n (CLAVE):**
```python
# LLM Agent decide qu√© datos pedir din√°micamente
agent_prompt = f"""
Current market: {symbol} at {price}
News sentiment: {sentiment_score}

Should we fetch:
1. Insider transactions? (SEC)
2. Macro indicators? (FRED)
3. Reddit sentiment? (PRAW)

Respond with tools to invoke.
"""

tools_invoked = llm_agent(agent_prompt)  # ["fetch_sec", "fetch_reddit"]
```

**Eficiencia:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (on-demand, no data waste)

---

## üÜö Comparaci√≥n de Fuentes de Datos

### 1. Datos Estructurados (OHLCV)

| Fuente | Frecuencia | Hist√≥rico | Costo | Latencia | Calidad Spread |
|--------|------------|-----------|-------|----------|----------------|
| **MT5 Broker** (tu actual) | 1-min | 5 a√±os | **GRATIS** | Real-time | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (real) |
| yfinance | 1-min | 7 d√≠as | **GRATIS** | 15-min delay | ‚≠ê‚≠ê‚òÜ‚òÜ‚òÜ (sint√©tico) |
| Alpha Vantage | 1-min | 2 a√±os | $50/mes | Real-time | ‚≠ê‚≠ê‚≠ê‚òÜ‚òÜ |
| Dukascopy | Tick | 10 a√±os | $500/a√±o | N/A | ‚≠ê‚≠ê‚≠ê‚≠ê‚òÜ |

**Recomendaci√≥n:** ‚úÖ **Mantener MT5 broker** (mejor calidad para Forex)

---

### 2. Datos No Estructurados (Sentiment)

| Fuente | Tipo | Cobertura | Costo | API | Calidad |
|--------|------|-----------|-------|-----|---------|
| **NewsAPI** | News headlines | Global | $449/mes | REST | ‚≠ê‚≠ê‚≠ê‚≠ê‚òÜ |
| **Alpha Vantage News** | Financial news | US-focused | $50/mes | REST | ‚≠ê‚≠ê‚≠ê‚òÜ‚òÜ |
| **Reddit (PRAW)** | Retail sentiment | r/forex, r/wallstreetbets | **GRATIS** | Python lib | ‚≠ê‚≠ê‚≠ê‚≠ê‚òÜ |
| **Twitter/X API v2** | Real-time tweets | Finance accounts | **GRATIS** (100/mes) | REST | ‚≠ê‚≠ê‚≠ê‚òÜ‚òÜ |
| **RSS Scraping** | Manual scraping | Investing.com, FXStreet | **GRATIS** | BeautifulSoup | ‚≠ê‚≠ê‚≠ê‚òÜ‚òÜ |
| **FinancialModelingPrep** | News + sentiment | US markets | $15/mes | REST | ‚≠ê‚≠ê‚≠ê‚≠ê‚òÜ |

**Recomendaci√≥n para FASE 1 (Gratuito):**
```
‚úÖ Reddit (PRAW): Retail sentiment (alta correlaci√≥n con volatilidad)
‚úÖ RSS Scraping: Titulares de Investing.com, FXStreet
‚úÖ Twitter/X Free Tier: 100 requests/mes (b√∫squedas clave: "$EURUSD", "forex")
```

**Recomendaci√≥n para FASE 2 (Paid):**
```
üìà Alpha Vantage News ($50/mes): Better quality, lower noise
üìà FinancialModelingPrep ($15/mes): Pre-computed sentiment scores
```

---

### 3. Datos Fundamentales/Macro

| Fuente | Tipo | Cobertura | Costo | API | Actualizaci√≥n |
|--------|------|-----------|-------|-----|---------------|
| **FRED (Federal Reserve)** | Macro indicators | US economy | **GRATIS** | REST | Daily |
| **SEC Edgar** | Insider trades, filings | US stocks | **GRATIS** | REST | Daily |
| **yfinance** | Fundamentals | Global stocks | **GRATIS** | Python lib | Daily |
| **World Bank Open Data** | Global macro | International | **GRATIS** | REST | Quarterly |

**Recomendaci√≥n para Forex:**
```
‚úÖ FRED: Fed Funds Rate (DFF), Yield Curve (T10Y2Y), Unemployment
‚úÖ VIX (via yfinance): S&P 500 volatility (alta correlaci√≥n con EUR/USD)
‚ö†Ô∏è SEC Edgar: Menos relevante para Forex (usar solo si trades acciones/ETFs)
```

---

## üèóÔ∏è Arquitectura Propuesta (Patr√≥n AlphaQuanter)

### Dise√±o de 3 Capas

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CAPA 1: DATA COLLECTORS (As√≠ncrono)                        ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ ‚îÇ MT5 Stream   ‚îÇ  ‚îÇ Reddit Bot   ‚îÇ  ‚îÇ FRED Poller  ‚îÇ      ‚îÇ
‚îÇ ‚îÇ (1-min OHLCV)‚îÇ  ‚îÇ (r/forex)    ‚îÇ  ‚îÇ (Daily)      ‚îÇ      ‚îÇ
‚îÇ ‚îÇ Real-time    ‚îÇ  ‚îÇ 15-min poll  ‚îÇ  ‚îÇ 24h cache    ‚îÇ      ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ           ‚Üì               ‚Üì               ‚Üì                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CAPA 2: FEATURE STORE (TimescaleDB + Redis)                ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ ‚îÇ TimescaleDB (Long-term storage)                     ‚îÇ    ‚îÇ
‚îÇ ‚îÇ - ohlcv_data (hypertable, 5 a√±os, 1-min)          ‚îÇ    ‚îÇ
‚îÇ ‚îÇ - sentiment_scores (24h rolling window)            ‚îÇ    ‚îÇ
‚îÇ ‚îÇ - macro_indicators (daily, FRED)                   ‚îÇ    ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ ‚îÇ Redis (Hot cache)                                   ‚îÇ    ‚îÇ
‚îÇ ‚îÇ - last_100_bars (OHLCV)                            ‚îÇ    ‚îÇ
‚îÇ ‚îÇ - current_sentiment (expires 1h)                   ‚îÇ    ‚îÇ
‚îÇ ‚îÇ - regime_prediction (expires 15min)                ‚îÇ    ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CAPA 3: FEATURE ENGINEERING (DRL State Builder)            ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ ‚îÇ StateVectorBuilder.build()                          ‚îÇ    ‚îÇ
‚îÇ ‚îÇ ‚Üí [price, MACD, RSI, ATR, sentiment, regime, VIX] ‚îÇ    ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ ‚îÇ LLM Orchestrator (on-demand)                        ‚îÇ    ‚îÇ
‚îÇ ‚îÇ if sentiment_stale > 1h:                            ‚îÇ    ‚îÇ
‚îÇ ‚îÇ     fetch_reddit_sentiment()                        ‚îÇ    ‚îÇ
‚îÇ ‚îÇ if vix_change > 5%:                                 ‚îÇ    ‚îÇ
‚îÇ ‚îÇ     fetch_fred_macro()                              ‚îÇ    ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üíª Implementaci√≥n en Python

### 1. Data Collectors (As√≠ncrono)

#### A. MT5 Stream Collector (Ya tienes esto)
```python
# underdog/data/mt5_stream_collector.py

import asyncio
from underdog.core.connectors.mt5_connector import Mt5Connector

class MT5StreamCollector:
    """Async collector for real-time MT5 ticks"""
    
    def __init__(self, symbols: list[str]):
        self.connector = Mt5Connector()
        self.symbols = symbols
    
    async def stream_ticks(self):
        """Stream ticks to TimescaleDB"""
        while True:
            for symbol in self.symbols:
                tick = await self.connector.get_last_tick(symbol)
                await self.insert_to_db(tick)
            await asyncio.sleep(0.1)  # 10 ticks/second
```

#### B. Reddit Sentiment Collector (NUEVO)
```python
# underdog/data/reddit_collector.py

import praw
import asyncio
from datetime import datetime, timedelta

class RedditSentimentCollector:
    """Collect sentiment from r/forex, r/wallstreetbets"""
    
    def __init__(self):
        self.reddit = praw.Reddit(
            client_id="YOUR_CLIENT_ID",
            client_secret="YOUR_SECRET",
            user_agent="underdog-bot"
        )
        self.subreddits = ['forex', 'wallstreetbets']
    
    async def collect_sentiment(self, symbol: str):
        """
        Collect last 24h posts mentioning symbol
        Returns: List of (timestamp, text, score)
        """
        posts = []
        for sub_name in self.subreddits:
            subreddit = self.reddit.subreddit(sub_name)
            
            # Search posts mentioning symbol
            query = f"{symbol} OR ${symbol}"
            for post in subreddit.search(query, time_filter='day', limit=100):
                if datetime.utcfromtimestamp(post.created_utc) > datetime.utcnow() - timedelta(hours=24):
                    posts.append({
                        'timestamp': post.created_utc,
                        'text': post.title + ' ' + post.selftext,
                        'score': post.score,
                        'subreddit': sub_name
                    })
        
        return posts
    
    async def poll_loop(self):
        """Poll every 15 minutes"""
        while True:
            try:
                posts = await self.collect_sentiment('EURUSD')
                # Process with FinGPT
                sentiment_score = await self.process_sentiment(posts)
                await self.save_to_db(sentiment_score)
            except Exception as e:
                logger.error(f"Reddit poll error: {e}")
            
            await asyncio.sleep(900)  # 15 minutes
```

#### C. FRED Macro Collector (NUEVO)
```python
# underdog/data/fred_collector.py

import aiohttp
from datetime import datetime

class FREDCollector:
    """Collect FRED macro indicators"""
    
    FRED_API_KEY = "YOUR_FREE_API_KEY"  # https://fred.stlouisfed.org/docs/api/api_key.html
    BASE_URL = "https://api.stlouisfed.org/fred/series/observations"
    
    INDICATORS = {
        'DFF': 'Fed Funds Rate',
        'T10Y2Y': 'Yield Curve',
        'VIXCLS': 'VIX',
        'UNRATE': 'Unemployment Rate'
    }
    
    async def fetch_indicator(self, series_id: str):
        """Fetch latest value for indicator"""
        async with aiohttp.ClientSession() as session:
            params = {
                'series_id': series_id,
                'api_key': self.FRED_API_KEY,
                'file_type': 'json',
                'limit': 1,
                'sort_order': 'desc'
            }
            
            async with session.get(self.BASE_URL, params=params) as resp:
                data = await resp.json()
                latest = data['observations'][0]
                
                return {
                    'indicator': series_id,
                    'value': float(latest['value']),
                    'date': latest['date']
                }
    
    async def poll_loop(self):
        """Poll daily (FRED updates once per day)"""
        while True:
            try:
                for series_id in self.INDICATORS.keys():
                    data = await self.fetch_indicator(series_id)
                    await self.save_to_db(data)
            except Exception as e:
                logger.error(f"FRED poll error: {e}")
            
            await asyncio.sleep(86400)  # 24 hours
```

---

### 2. Feature Store (TimescaleDB + Redis)

#### TimescaleDB Schema
```sql
-- OHLCV Data (ya tienes esto de MT5)
CREATE TABLE ohlcv_data (
    time TIMESTAMPTZ NOT NULL,
    symbol TEXT NOT NULL,
    open DOUBLE PRECISION,
    high DOUBLE PRECISION,
    low DOUBLE PRECISION,
    close DOUBLE PRECISION,
    volume BIGINT,
    spread DOUBLE PRECISION
);

SELECT create_hypertable('ohlcv_data', 'time');

-- Sentiment Scores (NUEVO)
CREATE TABLE sentiment_scores (
    time TIMESTAMPTZ NOT NULL,
    symbol TEXT NOT NULL,
    source TEXT,  -- 'reddit', 'twitter', 'news'
    score DOUBLE PRECISION,  -- [-1, 1]
    confidence DOUBLE PRECISION,
    text_sample TEXT
);

SELECT create_hypertable('sentiment_scores', 'time');

-- Macro Indicators (NUEVO)
CREATE TABLE macro_indicators (
    time TIMESTAMPTZ NOT NULL,
    indicator TEXT NOT NULL,  -- 'DFF', 'VIX', etc.
    value DOUBLE PRECISION
);

SELECT create_hypertable('macro_indicators', 'time');

-- Continuous Aggregate: 1h Average Sentiment
CREATE MATERIALIZED VIEW sentiment_1h
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 hour', time) AS bucket,
    symbol,
    AVG(score) as avg_sentiment,
    COUNT(*) as sample_count
FROM sentiment_scores
GROUP BY bucket, symbol;
```

#### Redis Cache Layer
```python
# underdog/data/feature_cache.py

import redis
import json
from datetime import timedelta

class FeatureCache:
    """Redis cache for hot features"""
    
    def __init__(self):
        self.redis = redis.Redis(host='localhost', port=6379, db=0)
    
    def set_sentiment(self, symbol: str, score: float, ttl_hours: int = 1):
        """Cache sentiment with 1h expiration"""
        key = f"sentiment:{symbol}"
        self.redis.setex(
            key,
            timedelta(hours=ttl_hours),
            json.dumps({'score': score, 'timestamp': datetime.utcnow().isoformat()})
        )
    
    def get_sentiment(self, symbol: str) -> float | None:
        """Get cached sentiment or None if stale"""
        key = f"sentiment:{symbol}"
        data = self.redis.get(key)
        if data:
            return json.loads(data)['score']
        return None
    
    def set_regime(self, symbol: str, regime: str, confidence: float):
        """Cache regime prediction (15 min expiry)"""
        key = f"regime:{symbol}"
        self.redis.setex(
            key,
            timedelta(minutes=15),
            json.dumps({'regime': regime, 'confidence': confidence})
        )
```

---

### 3. Feature Engineering (State Builder)

```python
# underdog/ml/feature_engineering.py

import numpy as np
import pandas as pd
from underdog.data.feature_cache import FeatureCache
from underdog.ml.sentiment_analyzer import FinGPTSentimentAnalyzer

class StateVectorBuilder:
    """
    Build DRL state vector from multiple data sources
    
    State Vector:
    [price, returns, ATR, MACD, RSI, BB_width, 
     sentiment, regime_onehot(3), VIX, fed_funds_rate]
    
    Total dimensions: 14
    """
    
    def __init__(self):
        self.cache = FeatureCache()
        self.sentiment_analyzer = FinGPTSentimentAnalyzer()
    
    async def build_state(self, symbol: str, current_bar: pd.Series) -> np.ndarray:
        """
        Build state vector for current bar
        
        Args:
            symbol: Trading symbol
            current_bar: Latest OHLCV bar with indicators
        
        Returns:
            state: np.array of shape (14,)
        """
        
        # 1. Price features (4)
        price = current_bar['close']
        returns = np.log(price / current_bar['close'].shift(1))
        atr = current_bar['atr']
        
        # 2. Technical indicators (3)
        macd = current_bar['macd']
        rsi = current_bar['rsi']
        bb_width = current_bar['bb_width']
        
        # 3. Sentiment (1) - from cache or fetch
        sentiment = self.cache.get_sentiment(symbol)
        if sentiment is None:
            # Fetch and cache (async)
            sentiment = await self.fetch_sentiment(symbol)
            self.cache.set_sentiment(symbol, sentiment)
        
        # 4. Regime (3) - one-hot encoding
        regime_data = self.cache.get_regime(symbol)
        if regime_data:
            regime = regime_data['regime']
            regime_onehot = self._encode_regime(regime)
        else:
            regime_onehot = np.array([0, 0, 1])  # Default: transition
        
        # 5. Macro (2)
        vix = await self.get_macro('VIXCLS')
        fed_funds = await self.get_macro('DFF')
        
        # Combine into state vector
        state = np.array([
            price,
            returns,
            atr,
            macd,
            rsi,
            bb_width,
            sentiment,
            *regime_onehot,  # 3 values
            vix,
            fed_funds
        ])
        
        return state
    
    def _encode_regime(self, regime: str) -> np.ndarray:
        """One-hot encode regime"""
        mapping = {'trend': [1, 0, 0], 'range': [0, 1, 0], 'transition': [0, 0, 1]}
        return np.array(mapping.get(regime, [0, 0, 1]))
    
    async def fetch_sentiment(self, symbol: str) -> float:
        """Fetch sentiment on-demand (LLM Orchestrator pattern)"""
        # Get last 24h Reddit posts
        posts = await self.reddit_collector.collect_sentiment(symbol)
        
        # Process with FinGPT
        texts = [p['text'] for p in posts]
        sentiments = self.sentiment_analyzer.analyze_batch(texts)
        
        # Weighted average by post score
        weights = np.array([p['score'] for p in posts])
        avg_sentiment = np.average(sentiments, weights=weights)
        
        return avg_sentiment
    
    async def get_macro(self, indicator: str) -> float:
        """Get macro indicator from cache or DB"""
        key = f"macro:{indicator}"
        cached = self.cache.redis.get(key)
        
        if cached:
            return float(cached)
        
        # Fetch from TimescaleDB
        value = await self.db.fetch_latest_macro(indicator)
        self.cache.redis.setex(key, timedelta(hours=24), str(value))
        
        return value
```

---

## üìä Comparaci√≥n de Eficiencia

### Arquitectura Actual (Solo MT5)
```
Data Sources: 1 (MT5)
Features: 8 (OHLC + technical indicators)
Update Frequency: Real-time
Cost: ‚Ç¨0

Ventajas:
‚úÖ Baja latencia
‚úÖ Alta calidad (spreads reales)
‚úÖ Gratis

Desventajas:
‚ùå Sin sentiment (blind to news)
‚ùå Sin macro context (Fed decisions, NFP)
‚ùå Sin regime adaptation
```

### Arquitectura Propuesta (H√≠brida con Papers)
```
Data Sources: 4 (MT5 + Reddit + FRED + RSS)
Features: 14 (OHLC + indicators + sentiment + regime + macro)
Update Frequency: 
  - OHLCV: Real-time
  - Sentiment: 15 min
  - Macro: Daily
Cost: ‚Ç¨0 (fase 1 gratuita)

Ventajas:
‚úÖ Alternative data (sentiment)
‚úÖ Macro context (Fed, VIX)
‚úÖ Regime-aware
‚úÖ Similar a papers (TD3 + LLM)
‚úÖ On-demand fetching (eficiente)

Desventajas:
‚ö†Ô∏è M√°s complejidad
‚ö†Ô∏è Dependencia de APIs externas
‚ö†Ô∏è Latencia sentiment (15 min)
```

**Eficiencia Estimada:**
- Papers demuestran **+15-30% Sharpe Ratio** con sentiment vs sin sentiment
- **-20% drawdown** con regime switching vs estrategia fija
- **ROI:** ‚Ç¨0 costo ‚Üí potencial +‚Ç¨500-1000/mes en FTMO

---

## üéØ Roadmap de Implementaci√≥n

### Fase 1: Gratuito (Semana 1-2)
```
1. [2h] Setup TimescaleDB + Redis
2. [3h] Reddit Collector (PRAW)
3. [2h] FRED Collector
4. [4h] FinGPT Sentiment Pipeline
5. [3h] StateVectorBuilder
6. [2h] Unit tests

Total: 16 horas
Costo: ‚Ç¨0
```

### Fase 2: Paid Upgrade (Opcional, Semana 3)
```
1. [1h] Alpha Vantage News API ($50/mes)
2. [2h] Integration with StateVectorBuilder
3. [1h] A/B testing: Free vs Paid sentiment

Total: 4 horas
Costo: ‚Ç¨50/mes (solo si mejora performance)
```

### Fase 3: Production (Semana 4)
```
1. [4h] Monitoring (Grafana dashboards)
2. [2h] Alertas data staleness
3. [2h] Fallback logic (si API falla)

Total: 8 horas
```

---

## üìå Recomendaci√≥n Final

**Para tu proyecto UNDERDOG:**

‚úÖ **MANTENER:** MT5 stream (mejor calidad Forex)

‚úÖ **A√ëADIR (Fase 1 - Gratuito):**
1. Reddit sentiment (PRAW) - 15 min updates
2. FRED macro (DFF, VIX) - daily updates
3. FinGPT sentiment pipeline (Hugging Face)

‚úÖ **CONSIDERAR (Fase 2 - Paid):**
1. Alpha Vantage News ($50/mes) - si Reddit insuficiente
2. NewsAPI ($449/mes) - solo si pasas FTMO Phase 1

‚ùå **EVITAR:**
- Tick data comercial (Dukascopy) - overkill para 1-min bars
- Bloomberg Terminal ($2000/mes) - no ROI para prop firm scale
- SEC Edgar - irrelevante para Forex

**Arquitectura elegida:** Patr√≥n **AlphaQuanter** (LLM Orchestrator + Feature Store)

**Papers implementados:**
- ‚úÖ arXiv:2510.10526v1: Sentiment integration (FinGPT)
- ‚úÖ arXiv:2510.03236v1: Regime features (RV, volatility)
- ‚úÖ AlphaQuanter: On-demand data fetching

**Timeline:** 3 semanas (16h Fase 1 + 8h tests + 4h Fase 2 opcional)

**Costo inicial:** ‚Ç¨0 (100% gratuito)

---

**√öltima actualizaci√≥n:** 2025-01-22  
**Status:** PROPUESTA - Ready for Implementation  
**Next Step:** ¬øAprobamos arquitectura h√≠brida o prefieres enfoque minimalista (solo Reddit + FRED)?
